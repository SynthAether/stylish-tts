training:
  # log training data every this number of steps
  log_interval: 1000
  # validate and save model every this number of steps
  save_interval: 5000
  # validate model every this number of steps
  val_interval: 5000
  device: "cuda"
  # Keep this as 'no' if you have the VRAM.
  # Lower precision slows training.
  # "bf16", "fp16", or "no" for no mixed precision
  mixed_precision: "no"
  # Reserve vRAM buffer during probe to avoid OOMs
  vram_reserve: 200
  data_workers: 32

# Number of epochs, max batch sizes and general learning rate of each stage.
training_plan:
  alignment:
    # alignment pretraining
    epochs: 20
    # Maximum number of segments per batch.
    probe_batch_max: 128
    # Learing Rate for this stage
    lr: 1e-5
  acoustic:
    # training of acoustic models and vocoder
    epochs: 10
    probe_batch_max: 16
    lr: 1e-4
  textual:
    # training for duration/pitch/energy from text
    epochs: 10
    probe_batch_max: 32
    lr: 3e-5
  style:
    # training for style from text
    epochs: 20
    probe_batch_max: 64
    lr: 1e-5
  joint:
    # Experimental joint training
    epochs: 10
    probe_batch_max: 16
    lr: 1e-5
  duration:
    epochs: 15
    probe_batch_max: 32
    lr: 1e-4

dataset:
  # All paths in this section are relative to the main path
  path: "path/to/your/dataset"
  train_data: "train-list.txt"
  val_data: "val-list.txt"
  wav_path: "wav-dir"
  pitch_path: "pitch.safetensors"
  alignment_path: "alignment.safetensors"
  alignment_model_path: "alignment_model.safetensors"

validation:
  # Number of samples to generate per validation step
  sample_count: 10
  # Specific segments to use for validation
  # force_samples:
  # - "filename.from.val_data.txt"
  # - "other.filename.from.val_data.txt"
  # - "other.other.filename.from.val_data.txt"


  # Weights are pre-tuned. Do not change these unless you
  # know what you are doing.
loss_weight:
  # mel reconstruction loss
  mel: 5
  # generator loss
  # -- if voice sounds autotuned, try increasing
  generator: 6
  # speech-language model feature matching loss
  slm: 0.2
  # pitch F0 reconstruction loss
  pitch: 3
  # energy reconstruction loss
  energy: 1
  # duration loss
  # -- if voice is too slow and pauses are too long, try increasing this and decreasing the other
  duration: 1
  # duration predictor probability output cross entropy loss
  # -- if voice is too fast and pauses are too short, try increasing this and decreasing the other
  duration_ce: 1
  # style reconstruction loss
  style: 1
  # magnitude loss
  mag: 1
  # phase loss
  # -- if voice sounds autotuned, try increasing
  phase: 8
  # Loss for predicting which parts of the segment are voiced/unvoiced
  voiced: 1
  # multi-phase loss
  multi_phase: 8
  # confidence for alignment (placeholder)
  confidence: 1
  # alignment loss
  align_loss: 1
  # discriminator loss (placeholder)
  discriminator: 1
